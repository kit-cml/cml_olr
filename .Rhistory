View(ordinaldf_test)
sd
ordinaldf[,1]
(ordinaldf[,1] - mean(ordinaldf[,1]))/sd(ordinaldf[,1])
ordinaldf[,1] <- (ordinaldf[,1] - mean(ordinaldf[,1]))/sd(ordinaldf[,1])
View(ordinaldf)
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/functions.R")
gc()
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
pair_id <- 1
# Select the row corresponding to pair_id
pair_row <- pairsdf[pair_id, ]
# Extract vectors of features and units
features_vector <- pair_row[grep("feature_", names(pair_row))]
units_vector <- pair_row[grep("unit_", names(pair_row))]
length(features_vector)
library(readr)
library(MASS)
library(pROC)
library(ggplot2)
library(foreach)
library(doParallel)
source("functions.r")
# Declare features
# features <- c("Comp.1",
#              "Comp.7")
# features <- c("LD1","LD2")
# features <- c("carest",
features <- c("qNet",
"dvdtmax",
"vmax",
"vrest",
"APD50",
"APD90",
"max_dv",
"camax",
"carest",
"CaTD50",
"CaTD90")
# units <- c("","")
# units <- c("","")
# units <- c("(mM)",
units <- c("(nC/uF)",
"(mV/ms)",
"(mV)",
"(mV)",
"(ms)",
"(ms)",
"(mV/ms)",
"(mM)",
"(mM)",
"(ms)",
"(ms)")
# Declare the file paths
# filepath_training <- "C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/0. Rscript_Multi_OLR/Results_LDA_PCA/resultPCA_training.csv"
# filepath_testing <- "C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/0. Rscript_Multi_OLR/Results_LDA_PCA/resultPCA_testing.csv"
# filepath_training <- "C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/0. Rscript_Multi_OLR/Results_LDA_PCA/resultLDA_training.csv"
# filepath_testing <- "C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/0. Rscript_Multi_OLR/Results_LDA_PCA/resultLDA_testing.csv"
# filepath_training <- "C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/data/4. dynamic_hERG_chantest/metrics_chantest_training_avg.csv"
# filepath_testing <- "C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/data/4. dynamic_hERG_chantest/metrics_chantest_testing_avg.csv"
filepath_training <- "C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/data/5. dynamic_hERG_li/metrics_li_training_avg.csv"
filepath_testing <- "C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/data/5. dynamic_hERG_li/metrics_li_testing_avg.csv"
# Set the number of tests
num_tests <- 1
# Set feature dimension
dimension <- 5
# Create pairsdf with all unique combinations
pairsdf <- pairsdfinitfun(features = features, units = units, dimension = dimension)
pair_id <- 1
# Select the row corresponding to pair_id
pair_row <- pairsdf[pair_id, ]
# Extract vectors of features and units
features_vector <- pair_row[grep("feature_", names(pair_row))]
units_vector <- pair_row[grep("unit_", names(pair_row))]
length(features_vector)
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
View(pairsdf)
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
name <- "check"
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
# Save the summarydf dataframe
write.csv(summarydf, paste(results_folder,"/","summary.csv", sep = ""), row.names = FALSE)
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
library(readr)
library(MASS)
library(pROC)
library(ggplot2)
library(foreach)
library(doParallel)
source("functions.r")
# Declare features
# features <- c("Comp.1",
#              "Comp.7")
# features <- c("LD1","LD2")
# features <- c("carest",
features <- c("qNet",
"dvdtmax",
"vmax",
"vrest",
"APD50",
"APD90",
"max_dv",
"camax",
"carest",
"CaTD50",
"CaTD90")
# units <- c("","")
# units <- c("","")
# units <- c("(mM)",
units <- c("(nC/uF)",
"(mV/ms)",
"(mV)",
"(mV)",
"(ms)",
"(ms)",
"(mV/ms)",
"(mM)",
"(mM)",
"(ms)",
"(ms)")
# Declare the file paths
# filepath_training <- "C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/0. Rscript_Multi_OLR/Results_LDA_PCA/resultPCA_training.csv"
# filepath_testing <- "C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/0. Rscript_Multi_OLR/Results_LDA_PCA/resultPCA_testing.csv"
# filepath_training <- "C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/0. Rscript_Multi_OLR/Results_LDA_PCA/resultLDA_training.csv"
# filepath_testing <- "C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/0. Rscript_Multi_OLR/Results_LDA_PCA/resultLDA_testing.csv"
# filepath_training <- "C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/data/4. dynamic_hERG_chantest/metrics_chantest_training_avg.csv"
# filepath_testing <- "C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/data/4. dynamic_hERG_chantest/metrics_chantest_testing_avg.csv"
filepath_training <- "C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/data/5. dynamic_hERG_li/metrics_li_training_avg.csv"
filepath_testing <- "C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/data/5. dynamic_hERG_li/metrics_li_testing_avg.csv"
# Set the number of tests
num_tests <- 1
# Set feature dimension
dimension <- 2
# Create pairsdf with all unique combinations
pairsdf <- pairsdfinitfun(features = features, units = units, dimension = dimension)
# Create the results folder
results_folder <- "results"
# Check if the folder exists
if (!dir.exists(results_folder)) {
# The folder does not exist, so create it
dir.create(results_folder)
cat("Folder created:", results_folder, "\n")
} else {
# The folder already exists
# List all files in the folder
files <- list.files(path = results_folder, full.names = TRUE)
# Remove all files in the folder
if (length(files) > 0) {
file.remove(files)
cat("All files in the folder have been removed.\n")
} else {
cat("The folder is already empty.\n")
}
}
pair_id <- 3
# Select the row corresponding to pair_id
pair_row <- pairsdf[pair_id, ]
# Extract vectors of features and units
features_vector <- pair_row[grep("feature_", names(pair_row))]
units_vector <- pair_row[grep("unit_", names(pair_row))]
# Print the current pair_id and features being processed
print(paste(c(pair_id, features_vector), collapse = "_"))
# Read in the training and testing datasets
training <- read_csv(filepath_training, show_col_types = FALSE)
testing <- read_csv(filepath_testing, show_col_types = FALSE)
# Determine if the analysis involves a single feature or multiple features
is_single <- length(features) == 1
# Construct a log file name based on the number of features
log_filename <- if (!is_single) {
paste(features_vector, collapse="_")
} else {
features_vector
}
logfile <- file(paste(results_folder,"/",paste(log_filename, "log.txt", sep="_"), sep = ""), open="wt")
# Dynamically select columns for the analysis based on features
# Include common columns like "label", "drug_name", "Sample_ID"
common_cols <- c("label", "drug_name", "Sample_ID")
training_cols <- as.character(c(features_vector, common_cols))
testing_cols <- as.character(c(features_vector, common_cols))
# Subset training and testing dataframes based on selected columns
ordinaldf <- training[, training_cols]
ordinaldf_test <- testing[, testing_cols]
# Construct dataset for training and testing
levels <- c("low", "intermediate", "high")
values <- c(1, 2, 3)
ordinaldf$label <- as.integer(factor(ordinaldf$label, levels = levels, labels = values))
ordinaldf_test$label <- as.integer(factor(ordinaldf_test$label, levels = levels, labels = values))
ordinaldf$label <- as.factor(ordinaldf$label)
ordinaldf_test$label <- as.factor(ordinaldf_test$label)
# Remove errors
ordinaldf <- na.omit(ordinaldf)
ordinaldf_test <- na.omit(ordinaldf_test)
# Normalize the data
# Calculate mean and SD for the first m columns of ordinaldf
dimension <- length(features_vector)
means <- sapply(ordinaldf[1:dimension], mean)
sds <- sapply(ordinaldf[1:dimension], sd)
tempdf <- ordinaldf
tempdf[1:dimension] <- mapply(function(x, mean, sd) (x - mean) / sd, ordinaldf[1:dimension], means, sds)
ordinaldf <- tempdf
tempdf <- ordinaldf_test
tempdf[1:dimension] <- mapply(function(x, mean, sd) (x - mean) / sd, ordinaldf_test[1:dimension], means, sds)
ordinaldf_test <- tempdf
# Fit the ordinal logistic regression model
# Prepare the formula for logistic regression based on the number of features
formula_string <- paste("label ~", paste(features_vector[1:dimension], collapse = " + "))
formula <- as.formula(formula_string)
# Specify the number of attempts
max_attempts <- 10000
# Flag to check if the model has converged
converged <- FALSE
# First trial without start option
tryCatch({
# Attempt to fit the model without specifying start
mod <- polr(formula, data = ordinaldf, Hess = TRUE)
converged <- TRUE
}, error = function(e) {
write(sprintf("First trial without 'start' failed. Retrying..."),logfile)
})
# If the first trial fails, attempt to fit with random starting values
attempts <- as.integer(0)
if (!converged) {
for (attemp_idx in 1:max_attempts) {
# Generate random starting values
start_values <- rnorm(dimension + 2, mean = 0.0, sd = 100.0)
# Attempt to fit the model with random starting values
tryCatch({
mod <- polr(formula, data = ordinaldf, start = start_values, Hess = TRUE)
converged <- TRUE
break
}, error = function(e) {
attempts <- attempts + 1
})
}
}
# If all attempts fail, print a message
if (!converged) {
write(sprintf("Could not fit the model after %d attempts",max_attempts),logfile)
} else {
# Make predictions for training dataset
predicted_labels <- predict(mod, newdata = ordinaldf, type = "class")
# Variables from Ordinal Logistic Regression model
alphas <- as.numeric(mod$zeta)  # Alpha values
betas <- as.numeric(mod$coefficients)  # Beta coefficients for all features
if (!is_single) {
# Apply TMS function row-wise efficiently
ordinaldf$TMS <- apply(ordinaldf[, 1:dimension], 1, function(row) TMS(alphas, betas, row))
ordinaldf_test$TMS <- apply(ordinaldf_test[, 1:dimension], 1, function(row) TMS(alphas, betas, row))
}
}
if (dimension == 2) {
scatterplotfun(data = ordinaldf,
mod = mod,
feature_1 = as.character(features_vector[1]),
feature_2 = as.character(features_vector[2]),
unit_1 = as.character(units_vector[1]),
unit_2 = as.character(units_vector[2]),
is_converged = converged,
is_training = TRUE,
is_legend = FALSE)
scatterplotfun(data = ordinaldf_test,
mod = mod,
feature_1 = as.character(features_vector[1]),
feature_2 = as.character(features_vector[2]),
unit_1 = as.character(units_vector[1]),
unit_2 = as.character(units_vector[2]),
is_converged = converged,
is_training = FALSE,
is_legend = FALSE)
}
# Determine if the analysis involves a single feature or multiple features
is_single <- length(features) == 1
# Construct a log file name based on the number of features
log_filename <- if (!is_single) {
paste(features_vector, collapse="_")
} else {
features_vector
}
logfile <- file(paste(results_folder,"/",paste(log_filename, "log.txt", sep="_"), sep = ""), open="wt")
# Dynamically select columns for the analysis based on features
# Include common columns like "label", "drug_name", "Sample_ID"
common_cols <- c("label", "drug_name", "Sample_ID")
training_cols <- as.character(c(features_vector, common_cols))
testing_cols <- as.character(c(features_vector, common_cols))
# Subset training and testing dataframes based on selected columns
ordinaldf <- training[, training_cols]
ordinaldf_test <- testing[, testing_cols]
# Construct dataset for training and testing
levels <- c("low", "intermediate", "high")
values <- c(1, 2, 3)
ordinaldf$label <- as.integer(factor(ordinaldf$label, levels = levels, labels = values))
ordinaldf_test$label <- as.integer(factor(ordinaldf_test$label, levels = levels, labels = values))
ordinaldf$label <- as.factor(ordinaldf$label)
ordinaldf_test$label <- as.factor(ordinaldf_test$label)
# Remove errors
ordinaldf <- na.omit(ordinaldf)
ordinaldf_test <- na.omit(ordinaldf_test)
# Normalize the data
# Calculate mean and SD for the first m columns of ordinaldf
dimension <- length(features_vector)
means <- sapply(ordinaldf[1:dimension], mean)
sds <- sapply(ordinaldf[1:dimension], sd)
tempdf <- ordinaldf
tempdf[1:dimension] <- mapply(function(x, mean, sd) (x - mean) / sd, ordinaldf[1:dimension], means, sds)
ordinaldf <- tempdf
tempdf <- ordinaldf_test
tempdf[1:dimension] <- mapply(function(x, mean, sd) (x - mean) / sd, ordinaldf_test[1:dimension], means, sds)
ordinaldf_test <- tempdf
# Fit the ordinal logistic regression model
# Prepare the formula for logistic regression based on the number of features
formula_string <- paste("label ~", paste(features_vector[1:dimension], collapse = " + "))
formula <- as.formula(formula_string)
# Specify the number of attempts
max_attempts <- 10000
# Flag to check if the model has converged
converged <- FALSE
# First trial without start option
tryCatch({
# Attempt to fit the model without specifying start
mod <- polr(formula, data = ordinaldf, Hess = TRUE)
converged <- TRUE
}, error = function(e) {
write(sprintf("First trial without 'start' failed. Retrying..."),logfile)
})
# If the first trial fails, attempt to fit with random starting values
attempts <- as.integer(0)
if (!converged) {
for (attemp_idx in 1:max_attempts) {
# Generate random starting values
start_values <- rnorm(dimension + 2, mean = 0.0, sd = 100.0)
# Attempt to fit the model with random starting values
tryCatch({
mod <- polr(formula, data = ordinaldf, start = start_values, Hess = TRUE)
converged <- TRUE
break
}, error = function(e) {
attempts <- attempts + 1
})
}
}
# If all attempts fail, print a message
if (!converged) {
write(sprintf("Could not fit the model after %d attempts",max_attempts),logfile)
} else {
# Make predictions for training dataset
predicted_labels <- predict(mod, newdata = ordinaldf, type = "class")
# Variables from Ordinal Logistic Regression model
alphas <- as.numeric(mod$zeta)  # Alpha values
betas <- as.numeric(mod$coefficients)  # Beta coefficients for all features
if (!is_single) {
# Apply TMS function row-wise efficiently
ordinaldf$TMS <- apply(ordinaldf[, 1:dimension], 1, function(row) TMS(alphas, betas, row))
ordinaldf_test$TMS <- apply(ordinaldf_test[, 1:dimension], 1, function(row) TMS(alphas, betas, row))
}
}
dimension
scatterplotfun(data = ordinaldf,
mod = mod,
feature_1 = as.character(features_vector[1]),
feature_2 = as.character(features_vector[2]),
unit_1 = as.character(units_vector[1]),
unit_2 = as.character(units_vector[2]),
is_converged = converged,
is_training = TRUE,
is_legend = FALSE)
# Check the column index
idx_model_1 <- as.integer(which(colnames(data) == feature_1))
data <- ordinaldf
mod <- mod
feature_1 <- as.character(features_vector[1])
feature_2 <- as.character(features_vector[2])
unit_1 <- as.character(units_vector[1])
unit_2 <- as.character(units_vector[2])
is_converged <- converged
is_training <- TRUE
is_legend <- FALSE
# Check the column index
idx_model_1 <- as.integer(which(colnames(data) == feature_1))
idx_model_2 <- as.integer(which(colnames(data) == feature_2))
idx_label <- as.integer(which(colnames(data) == "label"))
if (is_converged) {
# Variables from Ordinal Logistic Regression model
alpha1 <- as.numeric(mod$zeta[1])
alpha2 <- as.numeric(mod$zeta[2])
beta1 <- as.numeric(mod$coefficients[1])
beta2 <- as.numeric(mod$coefficients[2])
# Some descriptions of decision boundaries
m <- - beta1 / beta2
c1 <- - 1.0 / beta2 * (- alpha1 + log(1.0 - 2.0 * exp(alpha1 - alpha2)))
c2 <- 1.0 / beta2 * (alpha1 + log(exp(alpha2 - alpha1) - 2.0))
}
# Create a meshgrid for contour plotting testing dataset
x <- seq(min(data[,idx_model_1]), max(data[,idx_model_1]), length.out = 100)
y <- seq(min(data[,idx_model_2]), max(data[,idx_model_2]), length.out = 100)
if (is_converged) {
z1 <- outer(x, y, Vectorize(function(x, y) calculate_B1(alpha1, alpha2, beta1, beta2, x, y)))
z2 <- outer(x, y, Vectorize(function(x, y) calculate_B2(alpha1, alpha2, beta1, beta2, x, y)))
}
if (is_training) {
title <- "Training dataset"
file_name <- "training"
} else {
title <- "Testing dataset"
file_name <- "testing"
}
jpeg(paste(feature_1,feature_2,file_name,"dataset.jpg",sep = "_"),quality = 100, units = "in", width = 5, height = 5, res = 300)
plot(data[,idx_model_1],
data[,idx_model_2],
xlab = paste(feature_1, unit_1, sep = " "),
ylab = paste(feature_2, unit_2, sep = " "),
main = title,
cex.axis = 1.5,
cex.lab = 1.5,
cex.main = 1.5,
cex = 0.5)
data[,idx_model_1]
as.numeric(data[,idx_model_1])
as.numeric(as.character(data[,idx_model_1]))
data
View(data)
data[,1]
data$qNet
data[feature_1]
data["qNet"]
plot(data[,idx_model_1],
data[,idx_model_2])
str(data)
ordinaldf
data <- data.frame(data)
plot(data[,idx_model_1],
data[,idx_model_2],
xlab = paste(feature_1, unit_1, sep = " "),
ylab = paste(feature_2, unit_2, sep = " "),
main = title,
cex.axis = 1.5,
cex.lab = 1.5,
cex.main = 1.5,
cex = 0.5)
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
setwd("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr")
setwd("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
setwd("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
gc()
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
setwd("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr")
source("C:/Users/USER-PC/OneDrive - Universitas Airlangga/5. CML/4. Data_Ali_E/5. MLR_ORD_TOMEK/cml_olr/main_multi.R")
